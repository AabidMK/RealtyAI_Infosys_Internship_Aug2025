{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4ae665-1bd5-4dac-af69-a405aedc9fd9",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42a5b4d-3998-424b-af93-fc657389ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db8048-78e7-495d-8fd8-4ea1953b001e",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d527b496-4347-4dab-8794-bcf995f40149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Real Estate Data V21.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55addfd-cd31-4abb-a9ba-74e91d3cf2fa",
   "metadata": {},
   "source": [
    "# Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a63a3d-40e1-47bd-a6a8-1c14fabe8b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (14528, 9)\n",
      "\n",
      "Columns: ['Name', 'Property Title', 'Price', 'Location', 'Total_Area', 'Price_per_SQFT', 'Description', 'Baths', 'Balcony']\n",
      "\n",
      "Data types:\n",
      " Name               object\n",
      "Property Title     object\n",
      "Price              object\n",
      "Location           object\n",
      "Total_Area          int64\n",
      "Price_per_SQFT    float64\n",
      "Description        object\n",
      "Baths               int64\n",
      "Balcony            object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      " Name              0\n",
      "Property Title    0\n",
      "Price             0\n",
      "Location          0\n",
      "Total_Area        0\n",
      "Price_per_SQFT    0\n",
      "Description       0\n",
      "Baths             0\n",
      "Balcony           0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate values: 8\n",
      "\n",
      "Unique values:\n",
      " Name               9998\n",
      "Property Title     6507\n",
      "Price               891\n",
      "Location           7050\n",
      "Total_Area         1774\n",
      "Price_per_SQFT     2094\n",
      "Description       14490\n",
      "Baths                 6\n",
      "Balcony               2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nData types:\\n\", df.dtypes)  \n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate values:\",df.duplicated().sum())  #gives exact  duplicate rows\n",
    "print(\"\\nUnique values:\\n\",df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8504299-0ec7-433f-9eee-941bad7ee070",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d8dc3b-134a-4b16-8f11-b1bfda8fbeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "\n",
    "    # 1. Price conversion to Lakhs\n",
    "    def convert_price_to_lakhs(price_str):\n",
    "        price_str = str(price_str).replace(\",\", \"\").strip()\n",
    "        match = re.match(r'â‚¹?\\s*([\\d]+(?:\\.\\d+)?)\\s*(L|Cr|Crore|Crores)?', price_str, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = float(match.group(1))\n",
    "            unit = match.group(2)\n",
    "            if unit and unit.lower().startswith(\"c\"):   # Crore\n",
    "                value *= 100\n",
    "            elif unit and unit.lower().startswith(\"l\"): # Lakh\n",
    "                value *= 1\n",
    "            else:  # Assume raw number in Rupees\n",
    "                value /= 1e5\n",
    "            return value\n",
    "        return np.nan\n",
    "\n",
    "    df[\"Price_Lakhs\"] = df[\"Price\"].apply(convert_price_to_lakhs)\n",
    "\n",
    "    # 2. Split Location into Locality & City\n",
    "    df['Location_split'] = df['Location'].str.split(',')\n",
    "    df['Locality'] = df['Location_split'].apply(lambda x: x[0].strip().lower() if x and len(x) > 0 else '')\n",
    "    df['City'] = df['Location_split'].apply(lambda x: x[-1].strip().lower() if x and len(x) > 0 else '')\n",
    "    df = df.drop(columns=[\"Location_split\"])\n",
    "\n",
    "    # 3. Extract BHK and RK\n",
    "    def extract_category(title):\n",
    "        if pd.isna(title):\n",
    "            return None, None\n",
    "    \n",
    "        title = str(title)\n",
    "    \n",
    "        # Check for BHK\n",
    "        bhk_match = re.search(r'(\\d+)\\s*BHK', title, re.IGNORECASE)\n",
    "        if bhk_match:\n",
    "            num = int(bhk_match.group(1))\n",
    "            return \"BHK\", f\"{num} BHK\"\n",
    "    \n",
    "        # Check for RK\n",
    "        rk_match = re.search(r'(\\d+)?\\s*RK', title, re.IGNORECASE)\n",
    "        if rk_match:\n",
    "            num = rk_match.group(1)\n",
    "            num = int(num) if num else 1   # if just \"RK\", assume 1 RK\n",
    "            return \"RK\", f\"{num} RK\"\n",
    "    \n",
    "        return None, None\n",
    "\n",
    "    df[[\"bhk_or_rk\", \"bhk_category\"]] = df[\"Property Title\"].apply(\n",
    "        lambda x: pd.Series(extract_category(x))\n",
    "    )\n",
    "\n",
    "    # 3.1 Extract numeric BHK/RK as integer (new column)\n",
    "    def extract_num(category):\n",
    "        if pd.isna(category):\n",
    "            return np.nan\n",
    "        match = re.search(r'(\\d+)', str(category))\n",
    "        return int(match.group(1)) if match else np.nan\n",
    "\n",
    "    df[\"BHK\"] = df[\"bhk_category\"].apply(extract_num)\n",
    "\n",
    "    # 4. Create binary flags\n",
    "    df['Balcony_flag'] = df['Balcony'].map({'Yes': 1, 'Y': 1, 'No': 0, 'N': 0}).fillna(0)\n",
    "    df['BHK_or_RK_flag'] = df['bhk_or_rk'].map({'BHK': 1, 'bhk': 1, 'RK': 0, 'rk': 0}).fillna(0)\n",
    "\n",
    "    # 5. Convert numeric columns\n",
    "    df['Total_Area'] = pd.to_numeric(df['Total_Area'], errors='coerce')\n",
    "    df['Price_per_SQFT'] = pd.to_numeric(df['Price_per_SQFT'], errors='coerce')\n",
    "\n",
    "    # 6. Keep only Top 30 Localities\n",
    "    locality_counts = df['Locality'].value_counts()\n",
    "    top_localities = locality_counts.nlargest(30).index.tolist()\n",
    "    df.loc[~df['Locality'].isin(top_localities), 'Locality'] = 'Other'\n",
    "\n",
    "    # 7. Print summary\n",
    "    print(\"Basic cleaning completed:\")\n",
    "    print(f\"- Dataset shape: {df.shape}\")\n",
    "    print(f\"- Valid price records: {df['Price_Lakhs'].notna().sum()}\")\n",
    "    print(f\"- Unique cities: {df['City'].nunique()}\")\n",
    "    print(f\"- Localities (including 'Other'): {df['Locality'].nunique()}\")\n",
    "    print(f\"- Extracted BHK or RK listings: {df['bhk_or_rk'].notna().sum()}\")\n",
    "    print(f\"- Extracted numeric BHK/RK values: {df['BHK'].notna().sum()}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7a05fa-494b-4b83-9dde-7787837bb8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning completed:\n",
      "- Dataset shape: (14528, 17)\n",
      "- Valid price records: 14528\n",
      "- Unique cities: 8\n",
      "- Localities (including 'Other'): 31\n",
      "- Extracted BHK or RK listings: 14483\n",
      "- Extracted numeric BHK/RK values: 14483\n"
     ]
    }
   ],
   "source": [
    "data_clean = data_cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2a286-4192-425e-ba1d-93f9abfde5e1",
   "metadata": {},
   "source": [
    "# Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e037512-dc21-4023-8a9e-cbc63dc9287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Applying outlier removal...\n",
      "    Removed 2642 outliers (18.2%)\n",
      "    Final shape: (11886, 17)\n"
     ]
    }
   ],
   "source": [
    "def outlier_removal(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\" Applying outlier removal...\")\n",
    "    \n",
    "    def remove_outliers_iqr(series, factor=1.5):\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        return (series >= lower_bound) & (series <= upper_bound)\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # Apply to key columns\n",
    "    price_mask = remove_outliers_iqr(df['Price_Lakhs'].dropna())\n",
    "    area_mask = remove_outliers_iqr(df['Total_Area'].dropna())\n",
    "    pps_mask = remove_outliers_iqr(df['Price_per_SQFT'].dropna())\n",
    "    \n",
    "    # Combine masks\n",
    "    valid_price_idx = df['Price_Lakhs'].dropna().index\n",
    "    combined_mask = price_mask & area_mask & pps_mask\n",
    "    outlier_idx = valid_price_idx[~combined_mask]\n",
    "    \n",
    "    df_clean = df.drop(outlier_idx)\n",
    "    \n",
    "    removed_count = initial_count - len(df_clean)\n",
    "    print(f\"    Removed {removed_count} outliers ({removed_count/initial_count*100:.1f}%)\")\n",
    "    print(f\"    Final shape: {df_clean.shape}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Apply proven outlier removal\n",
    "data_clean = outlier_removal(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb457e-8186-4294-9907-bf01a002fe21",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bb1e6a-51f2-4c4d-8bed-0b8e0573a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extra_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\" Creating EXTRA advanced features...\")\n",
    "    \n",
    "    # --- 1. Statistical transforms ---\n",
    "    df['log_price'] = np.log1p(df['Price_Lakhs'])\n",
    "    df['log_area'] = np.log1p(df['Total_Area'].clip(lower=1))\n",
    "    df['sqrt_area'] = np.sqrt(df['Total_Area'].clip(lower=0))\n",
    "    df['inv_area'] = 1 / np.maximum(df['Total_Area'], 1)\n",
    "    \n",
    "    # --- 2. Ratios & densities ---\n",
    "    df['Area_per_Bath'] = df['Total_Area'] / np.maximum(df['Baths'], 1)\n",
    "    df['Baths_per_BHK'] = df['Baths'] / np.maximum(df['BHK'], 1)\n",
    "    df['Area_per_Room'] = df['Total_Area'] / np.maximum(df['BHK'] + df['Baths'], 1)\n",
    "    df['log_area_per_room'] = np.log1p(df['Area_per_Room'])\n",
    "    df['Bath_to_BHK_ratio'] = df['Baths'] / np.maximum(df['BHK'], 1)\n",
    "    \n",
    "    # --- 3. Locality/City level features ---\n",
    "    df['Locality_Median_Price'] = df.groupby('Locality')[\"Price_Lakhs\"].transform(\"median\")\n",
    "    df['Price_vs_Locality'] = df['Price_Lakhs'] / df['Locality_Median_Price']\n",
    "    df['City_Median_Price'] = df.groupby('City')[\"Price_Lakhs\"].transform(\"median\")\n",
    "    df['Price_vs_City'] = df['Price_Lakhs'] / df['City_Median_Price']\n",
    "    \n",
    "    # --- 4. Boolean / Flags ---\n",
    "    df['is_BHK'] = (df['bhk_or_rk'].str.upper() == \"BHK\").astype(int)\n",
    "    df['is_RK'] = (df['bhk_or_rk'].str.upper() == \"RK\").astype(int)\n",
    "    df['is_Compact'] = (df['Total_Area'] < 500).astype(int)\n",
    "    df['is_Luxury'] = (df['Total_Area'] > 2000).astype(int)\n",
    "    df['Is_Premium_Size'] = (df['Total_Area'] > df['Total_Area'].median()).astype(int)\n",
    "    df['Has_Multiple_Baths'] = (df['Baths'] >= 2).astype(int)\n",
    "    df['Luxury_Score'] = df['is_Luxury'] + df['Has_Multiple_Baths'] + df['Balcony_flag']\n",
    "    \n",
    "    # --- 5. Text-derived features ---\n",
    "    df['is_apartment'] = df['Property Title'].str.contains(\"apartment\", case=False, na=False).astype(int)\n",
    "    df['is_villa'] = df['Property Title'].str.contains(\"villa\", case=False, na=False).astype(int)\n",
    "    df['is_studio'] = df['Property Title'].str.contains(\"studio\", case=False, na=False).astype(int)\n",
    "    df['is_penthouse'] = df['Property Title'].str.contains(\"penthouse\", case=False, na=False).astype(int)\n",
    "    \n",
    "    # --- 6. Interaction features ---\n",
    "    df['Area_x_Price'] = df['Total_Area'] * df['Price_per_SQFT']\n",
    "    df['Area_x_BHK'] = df['Total_Area'] * np.maximum(df['BHK'], 1)\n",
    "    df['Area_x_Baths'] = df['Total_Area'] * np.maximum(df['Baths'], 1)\n",
    "    df['log_Area_x_BHK'] = np.log1p(df['Area_x_BHK'])\n",
    "    df['BHK_x_Baths'] = df['BHK'] * df['Baths']\n",
    "    df['Balcony_x_BHK'] = df['Balcony_flag'] * df['BHK']\n",
    "    \n",
    "    # --- 7. Percentile based features ---\n",
    "    df['Area_percentile'] = df['Total_Area'].rank(pct=True)\n",
    "    df['Price_percentile'] = df['Price_Lakhs'].rank(pct=True)\n",
    "    \n",
    "    # --- 8. NEW: Missing features you need ---\n",
    "    df['Price_per_Room'] = df['Price_per_SQFT'] * df['Area_per_Room']\n",
    "    df['Total_Rooms'] = df['BHK'] + df['Baths']                       \n",
    "    df['Area_Efficiency'] = df['Total_Area'] / np.maximum(df['Total_Rooms'], 1) \n",
    "    \n",
    "    # Property size bins\n",
    "    def categorize_property_size(area):\n",
    "        if area < 500: return 'Compact'\n",
    "        elif area < 1000: return 'Medium'\n",
    "        elif area < 2000: return 'Large'\n",
    "        else: return 'Luxury'\n",
    "    \n",
    "    df['Property_Size_Category'] = df['Total_Area'].apply(categorize_property_size)\n",
    "    \n",
    "    # BHK Category\n",
    "    df['BHK_Category'] = df['BHK'].astype(str) + \" \" + df['bhk_or_rk'] \n",
    "    \n",
    "    # --- 9. Combined luxury score ---\n",
    "    def advanced_luxury_score(row):\n",
    "        score = 0\n",
    "        if row['Total_Area'] > 2000: score += 3\n",
    "        elif row['Total_Area'] > 1200: score += 2\n",
    "        elif row['Total_Area'] > 800: score += 1\n",
    "        \n",
    "        if row['BHK'] >= 4: score += 2\n",
    "        elif row['BHK'] >= 3: score += 1\n",
    "        \n",
    "        if row['Baths'] >= 3: score += 2\n",
    "        elif row['Baths'] >= 2: score += 1\n",
    "        \n",
    "        if row['Balcony_flag'] == 1: score += 1\n",
    "        if row['is_villa'] or row['is_penthouse']: score += 2\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    df['Advanced_Luxury_Score'] = df.apply(advanced_luxury_score, axis=1)\n",
    "    \n",
    "    print(f\" Extra features created. Total columns now: {df.shape[1]}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33aefe10-8d9a-453b-a5f6-f41d4a477216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating EXTRA advanced features...\n",
      " Extra features created. Total columns now: 55\n"
     ]
    }
   ],
   "source": [
    "data_featured = create_extra_features(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523b09d1-9a8a-4785-a475-2e22ad091b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Property Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Location</th>\n",
       "      <th>Total_Area</th>\n",
       "      <th>Price_per_SQFT</th>\n",
       "      <th>Description</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Balcony</th>\n",
       "      <th>Price_Lakhs</th>\n",
       "      <th>...</th>\n",
       "      <th>BHK_x_Baths</th>\n",
       "      <th>Balcony_x_BHK</th>\n",
       "      <th>Area_percentile</th>\n",
       "      <th>Price_percentile</th>\n",
       "      <th>Price_per_Room</th>\n",
       "      <th>Total_Rooms</th>\n",
       "      <th>Area_Efficiency</th>\n",
       "      <th>Property_Size_Category</th>\n",
       "      <th>BHK_Category</th>\n",
       "      <th>Advanced_Luxury_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casagrand ECR 14</td>\n",
       "      <td>4 BHK Flat for sale in Kanathur Reddikuppam, C...</td>\n",
       "      <td>â‚¹1.99 Cr</td>\n",
       "      <td>Kanathur Reddikuppam, Chennai</td>\n",
       "      <td>2583</td>\n",
       "      <td>7700.0</td>\n",
       "      <td>Best 4 BHK Apartment for modern-day lifestyle ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.997055</td>\n",
       "      <td>0.986160</td>\n",
       "      <td>2486137.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>322.875</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>4.0 BHK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAC Prapthi</td>\n",
       "      <td>3 BHK Flat for sale in West Tambaram, Chennai</td>\n",
       "      <td>â‚¹1.0 Cr</td>\n",
       "      <td>Kasthuribai Nagar, West Tambaram,Chennai</td>\n",
       "      <td>1320</td>\n",
       "      <td>7580.0</td>\n",
       "      <td>Property for sale in Tambaram, Chennai. This 3...</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.836572</td>\n",
       "      <td>1667600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>220.000</td>\n",
       "      <td>Large</td>\n",
       "      <td>3.0 BHK</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VGN Spring Field Phase 1</td>\n",
       "      <td>2 BHK Flat for sale in Avadi, Chennai</td>\n",
       "      <td>â‚¹48.0 L</td>\n",
       "      <td>Avadi, Chennai</td>\n",
       "      <td>960</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Property for sale in Avadi, Chennai. This 2 BH...</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.503407</td>\n",
       "      <td>0.421925</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>192.000</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0 BHK</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  \\\n",
       "0          Casagrand ECR 14   \n",
       "2               DAC Prapthi   \n",
       "4  VGN Spring Field Phase 1   \n",
       "\n",
       "                                      Property Title     Price  \\\n",
       "0  4 BHK Flat for sale in Kanathur Reddikuppam, C...  â‚¹1.99 Cr   \n",
       "2      3 BHK Flat for sale in West Tambaram, Chennai   â‚¹1.0 Cr   \n",
       "4              2 BHK Flat for sale in Avadi, Chennai   â‚¹48.0 L   \n",
       "\n",
       "                                   Location  Total_Area  Price_per_SQFT  \\\n",
       "0             Kanathur Reddikuppam, Chennai        2583          7700.0   \n",
       "2  Kasthuribai Nagar, West Tambaram,Chennai        1320          7580.0   \n",
       "4                            Avadi, Chennai         960          5000.0   \n",
       "\n",
       "                                         Description  Baths Balcony  \\\n",
       "0  Best 4 BHK Apartment for modern-day lifestyle ...      4     Yes   \n",
       "2  Property for sale in Tambaram, Chennai. This 3...      3      No   \n",
       "4  Property for sale in Avadi, Chennai. This 2 BH...      3     Yes   \n",
       "\n",
       "   Price_Lakhs  ... BHK_x_Baths Balcony_x_BHK Area_percentile  \\\n",
       "0        199.0  ...        16.0           4.0        0.997055   \n",
       "2        100.0  ...         9.0           0.0        0.786303   \n",
       "4         48.0  ...         6.0           2.0        0.503407   \n",
       "\n",
       "  Price_percentile  Price_per_Room  Total_Rooms  Area_Efficiency  \\\n",
       "0         0.986160       2486137.5          8.0          322.875   \n",
       "2         0.836572       1667600.0          6.0          220.000   \n",
       "4         0.421925        960000.0          5.0          192.000   \n",
       "\n",
       "   Property_Size_Category  BHK_Category  Advanced_Luxury_Score  \n",
       "0                  Luxury       4.0 BHK                      8  \n",
       "2                   Large       3.0 BHK                      5  \n",
       "4                  Medium       2.0 BHK                      4  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_featured.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d88f32b-4e34-43fc-958a-9b9bd72e96e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature Selection for Advanced Algorithms:\n",
      "   Numeric features: 13\n",
      "   Categorical features: 4\n",
      "   Final dataset shape: (11886, 18)\n",
      "   Missing values: 150\n",
      "   Sample size: 11886 properties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_area</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Balcony_flag</th>\n",
       "      <th>BHK_or_RK_flag</th>\n",
       "      <th>log_area_per_room</th>\n",
       "      <th>Bath_to_BHK_ratio</th>\n",
       "      <th>Total_Rooms</th>\n",
       "      <th>Area_Efficiency</th>\n",
       "      <th>Area_x_Baths</th>\n",
       "      <th>log_Area_x_BHK</th>\n",
       "      <th>Is_Premium_Size</th>\n",
       "      <th>Has_Multiple_Baths</th>\n",
       "      <th>Advanced_Luxury_Score</th>\n",
       "      <th>City</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Property_Size_Category</th>\n",
       "      <th>BHK_Category</th>\n",
       "      <th>Price_Lakhs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.857094</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.780358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>322.875</td>\n",
       "      <td>10332</td>\n",
       "      <td>9.243098</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>chennai</td>\n",
       "      <td>Other</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>4.0 BHK</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.186144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.398163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>220.000</td>\n",
       "      <td>3960</td>\n",
       "      <td>8.284252</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>chennai</td>\n",
       "      <td>Other</td>\n",
       "      <td>Large</td>\n",
       "      <td>3.0 BHK</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.867974</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.262690</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>192.000</td>\n",
       "      <td>2880</td>\n",
       "      <td>7.560601</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>chennai</td>\n",
       "      <td>avadi</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0 BHK</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_area  Baths  Balcony_flag  BHK_or_RK_flag  log_area_per_room  \\\n",
       "0  7.857094      4             1             1.0           5.780358   \n",
       "2  7.186144      3             0             1.0           5.398163   \n",
       "4  6.867974      3             1             1.0           5.262690   \n",
       "\n",
       "   Bath_to_BHK_ratio  Total_Rooms  Area_Efficiency  Area_x_Baths  \\\n",
       "0                1.0          8.0          322.875         10332   \n",
       "2                1.0          6.0          220.000          3960   \n",
       "4                1.5          5.0          192.000          2880   \n",
       "\n",
       "   log_Area_x_BHK  Is_Premium_Size  Has_Multiple_Baths  Advanced_Luxury_Score  \\\n",
       "0        9.243098                1                   1                      8   \n",
       "2        8.284252                1                   1                      5   \n",
       "4        7.560601                1                   1                      4   \n",
       "\n",
       "      City Locality Property_Size_Category BHK_Category  Price_Lakhs  \n",
       "0  chennai    Other                 Luxury      4.0 BHK        199.0  \n",
       "2  chennai    Other                  Large      3.0 BHK        100.0  \n",
       "4  chennai    avadi                 Medium      2.0 BHK         48.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = [\n",
    "    'log_area',              # log-transformed area\n",
    "    'Baths',                 # number of bathrooms\n",
    "    'Balcony_flag',          # balcony present or not\n",
    "    'BHK_or_RK_flag',        # whether property is BHK or RK\n",
    "    'log_area_per_room',\n",
    "    'Bath_to_BHK_ratio',     # more bathrooms per BHK â†’ luxury\n",
    "    'Total_Rooms',           # BHK + Baths\n",
    "    'Area_Efficiency',       # area per room       \n",
    "    'Area_x_Baths',\n",
    "    'log_Area_x_BHK',\n",
    "    'Is_Premium_Size',       # large property flag\n",
    "    'Has_Multiple_Baths',    # 2 or more baths         \n",
    "    'Advanced_Luxury_Score',\n",
    "    #'Price_per_Room'          # extended score\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'City',\n",
    "    'Locality',\n",
    "    'Property_Size_Category',\n",
    "    'BHK_Category'\n",
    "]\n",
    "\n",
    "target_column = 'Price_Lakhs'\n",
    "\n",
    "\n",
    "all_features = numeric_features + categorical_features\n",
    "\n",
    "final_data = data_featured[all_features + [target_column]].copy()\n",
    "final_data = final_data.dropna(subset=[target_column])\n",
    "\n",
    "print(\" Feature Selection for Advanced Algorithms:\")\n",
    "print(f\"   Numeric features: {len(numeric_features)}\")\n",
    "print(f\"   Categorical features: {len(categorical_features)}\")\n",
    "print(f\"   Final dataset shape: {final_data.shape}\")\n",
    "print(f\"   Missing values: {final_data.isnull().sum().sum()}\")\n",
    "print(f\"   Sample size: {len(final_data)} properties\")\n",
    "\n",
    "final_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e516240-166f-42aa-8d82-8f597fae1da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train-Test Split:\n",
      "   Training set: 9508 samples (80.0%)\n",
      "   Test set: 2378 samples (20.0%)\n",
      "   Features: 17\n"
     ]
    }
   ],
   "source": [
    "X = final_data.drop(columns=[target_column])\n",
    "y = final_data[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,  \n",
    "    random_state=42,\n",
    "    stratify=X['City']\n",
    ")\n",
    "\n",
    "print(f\" Train-Test Split:\")\n",
    "print(f\"   Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5977ff5-0339-40c9-a33b-c781ab149d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preparing Advanced Algorithm Pipeline...\n",
      " Data preprocessing complete:\n",
      "   Final features: 17\n",
      "   Training shape: (9508, 17)\n",
      "   Test shape: (2378, 17)\n",
      " No object columns remain. Data is ready for ML models.\n"
     ]
    }
   ],
   "source": [
    "# Advanced Algorithm Data Preparation\n",
    "print(\" Preparing Advanced Algorithm Pipeline...\")\n",
    "\n",
    "categorical_features = ['City', 'Locality', 'Property_Size_Category', 'BHK_Category']\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical features\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    combined_values = pd.concat([X_train[feature], X_test[feature]], ignore_index=True)\n",
    "    le.fit(combined_values.astype(str))\n",
    "    \n",
    "    # Encode train and test\n",
    "    X_train[f'{feature}_encoded'] = le.transform(X_train[feature].astype(str))\n",
    "    X_test[f'{feature}_encoded'] = le.transform(X_test[feature].astype(str))\n",
    "    \n",
    "    label_encoders[feature] = le  # store encoder\n",
    "\n",
    "# Use only numeric + encoded features\n",
    "features_to_use = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "X_train_processed = X_train[features_to_use].copy()\n",
    "X_test_processed = X_test[features_to_use].copy()\n",
    "\n",
    "# Convert any leftover object columns to numeric\n",
    "for col in X_train_processed.columns:\n",
    "    if X_train_processed[col].dtype == 'object':\n",
    "        print(f\"Converting {col} to numeric...\")\n",
    "        X_train_processed[col] = pd.to_numeric(X_train_processed[col], errors='coerce')\n",
    "        X_test_processed[col] = pd.to_numeric(X_test_processed[col], errors='coerce')\n",
    "\n",
    "# Fill missing values\n",
    "X_train_processed = X_train_processed.fillna(0)\n",
    "X_test_processed = X_test_processed.fillna(0)\n",
    "\n",
    "print(f\" Data preprocessing complete:\")\n",
    "print(f\"   Final features: {len(features_to_use)}\")\n",
    "print(f\"   Training shape: {X_train_processed.shape}\")\n",
    "print(f\"   Test shape: {X_test_processed.shape}\")\n",
    "\n",
    "# Check if any object columns remain\n",
    "object_cols = X_train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "if object_cols:\n",
    "    print(\"Remaining object columns:\", object_cols)\n",
    "else:\n",
    "    print(\" No object columns remain. Data is ready for ML models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1cf40a-9685-4da5-8c7b-e059813ec83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Random_Forest...\n",
      " Random_Forest Results:\n",
      "   Train RÂ²: 0.4750 (47.5%)\n",
      "   Test RÂ²: 0.4710 (47.1%)\n",
      "   Overfitting Gap: 0.84%\n",
      "   Test MAE: â‚¹22.01L\n",
      "   Test RMSE: â‚¹29.52L\n",
      "\n",
      " Training Extra_Trees...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prime\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_forest.py:612: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "C:\\Users\\Prime\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_forest.py:612: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extra_Trees Results:\n",
      "   Train RÂ²: 0.3805 (38.1%)\n",
      "   Test RÂ²: 0.3817 (38.2%)\n",
      "   Overfitting Gap: -0.32%\n",
      "   Test MAE: â‚¹23.94L\n",
      "   Test RMSE: â‚¹31.91L\n",
      "\n",
      " Training Gradient_Boosting...\n",
      " Gradient_Boosting Results:\n",
      "   Train RÂ²: 0.2680 (26.8%)\n",
      "   Test RÂ²: 0.2694 (26.9%)\n",
      "   Overfitting Gap: -0.54%\n",
      "   Test MAE: â‚¹26.64L\n",
      "   Test RMSE: â‚¹34.69L\n",
      "\n",
      " Training AdaBoost...\n",
      " AdaBoost Results:\n",
      "   Train RÂ²: 0.5189 (51.9%)\n",
      "   Test RÂ²: 0.4996 (50.0%)\n",
      "   Overfitting Gap: 3.71%\n",
      "   Test MAE: â‚¹21.55L\n",
      "   Test RMSE: â‚¹28.71L\n",
      "\n",
      " Training Bagging...\n",
      " Bagging Results:\n",
      "   Train RÂ²: 0.7323 (73.2%)\n",
      "   Test RÂ²: 0.5127 (51.3%)\n",
      "   Overfitting Gap: 29.98%\n",
      "   Test MAE: â‚¹20.24L\n",
      "   Test RMSE: â‚¹28.33L\n",
      "\n",
      " Training XGBoost...\n",
      " XGBoost Results:\n",
      "   Train RÂ²: 0.2660 (26.6%)\n",
      "   Test RÂ²: 0.2686 (26.9%)\n",
      "   Overfitting Gap: -0.99%\n",
      "   Test MAE: â‚¹26.62L\n",
      "   Test RMSE: â‚¹34.70L\n",
      "\n",
      " Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1391\n",
      "[LightGBM] [Info] Number of data points in the train set: 9508, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 65.100723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      " LightGBM Results:\n",
      "   Train RÂ²: 0.2647 (26.5%)\n",
      "   Test RÂ²: 0.2686 (26.9%)\n",
      "   Overfitting Gap: -1.45%\n",
      "   Test MAE: â‚¹26.66L\n",
      "   Test RMSE: â‚¹34.71L\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "string_cols = X_train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "results = {}\n",
    "    \n",
    "models = {\n",
    "    'Random_Forest': RandomForestRegressor(\n",
    "        n_estimators=12,\n",
    "        max_depth=2,\n",
    "        min_samples_split=40,\n",
    "        min_samples_leaf=20,\n",
    "        max_features=0.15,\n",
    "        random_state=42,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Extra_Trees': ExtraTreesRegressor(\n",
    "        n_estimators=15,\n",
    "        max_depth=2,\n",
    "        min_samples_split=30,\n",
    "        min_samples_leaf=15,\n",
    "        max_features=0.2,\n",
    "        random_state=42,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient_Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=15,\n",
    "        max_depth=2,\n",
    "        min_samples_split=30,\n",
    "        min_samples_leaf=20,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.5,\n",
    "        max_features=0.2,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostRegressor(\n",
    "        n_estimators=10,\n",
    "        learning_rate=0.3,\n",
    "        loss='linear',\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Bagging': BaggingRegressor(\n",
    "        n_estimators=15,\n",
    "        max_samples=0.6,\n",
    "        max_features=0.6,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=15,\n",
    "        max_depth=2,\n",
    "        min_child_weight=15,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=0.2,\n",
    "        reg_alpha=3.0,\n",
    "        reg_lambda=3.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "   'LightGBM': LGBMRegressor(\n",
    "    n_estimators=15,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=20,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=0.2,\n",
    "    reg_alpha=3.0,\n",
    "    reg_lambda=3.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "}\n",
    "    \n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Training {name}...\")\n",
    "        \n",
    "    model.fit(X_train_processed, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_processed)\n",
    "    y_test_pred = model.predict(X_test_processed)\n",
    "        \n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        \n",
    "    overfitting_gap = train_r2 - test_r2\n",
    "    overfitting_pct = (overfitting_gap / train_r2) * 100\n",
    "        \n",
    "    results[name] = {\n",
    "        'Train_R2': train_r2,\n",
    "        'Test_R2': test_r2,\n",
    "        'Train_MAE': train_mae,\n",
    "        'Test_MAE': test_mae,\n",
    "        'Train_RMSE': train_rmse,\n",
    "        'Test_RMSE': test_rmse,\n",
    "        'Overfitting_Gap_%': overfitting_pct\n",
    "    }\n",
    "        \n",
    "    print(f\" {name} Results:\")\n",
    "    print(f\"   Train RÂ²: {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "    print(f\"   Test RÂ²: {test_r2:.4f} ({test_r2*100:.1f}%)\")\n",
    "    print(f\"   Overfitting Gap: {overfitting_pct:.2f}%\")\n",
    "    print(f\"   Test MAE: â‚¹{test_mae:.2f}L\")\n",
    "    print(f\"   Test RMSE: â‚¹{test_rmse:.2f}L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd0a707d-569c-457b-97dc-b40f4a80091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ADVANCED ALGORITHM PERFORMANCE RANKING:\n",
      "               Model  Train_R2   Test_R2  Overfitting_Gap_%   Test_MAE  \\\n",
      "4            Bagging  0.732251  0.512727          29.979319  20.235764   \n",
      "3           AdaBoost  0.518869  0.499609           3.711907  21.545764   \n",
      "0      Random_Forest  0.474962  0.470994           0.835295  22.011337   \n",
      "1        Extra_Trees  0.380528  0.381748          -0.320764  23.937521   \n",
      "2  Gradient_Boosting  0.267970  0.269423          -0.542003  26.640973   \n",
      "5            XGBoost  0.266009  0.268634          -0.986947  26.624130   \n",
      "6           LightGBM  0.264720  0.268556          -1.449350  26.663286   \n",
      "\n",
      "   Test_RMSE  \n",
      "4  28.327489  \n",
      "3  28.706270  \n",
      "0  29.515633  \n",
      "1  31.908366  \n",
      "2  34.686060  \n",
      "5  34.704772  \n",
      "6  34.706621  \n",
      "\n",
      " BEST PERFORMING MODEL: Bagging\n",
      "   Train RÂ²: 0.7323 \n",
      "   Test RÂ²: 0.5127 \n",
      "   Overfitting Gap: 30.0%\n",
      "   Test MAE: â‚¹20.24L\n",
      "   Test RMSE: â‚¹28.33L\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive performance comparison\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Train_R2': [results[model]['Train_R2'] for model in results],\n",
    "    'Test_R2': [results[model]['Test_R2'] for model in results],\n",
    "    'Overfitting_Gap_%': [results[model]['Overfitting_Gap_%'] for model in results],\n",
    "    'Test_MAE': [results[model]['Test_MAE'] for model in results],\n",
    "    'Test_RMSE': [results[model]['Test_RMSE'] for model in results]\n",
    "})\n",
    "\n",
    "\n",
    "performance_df = performance_df.sort_values('Test_R2', ascending=False)\n",
    "\n",
    "print(\" ADVANCED ALGORITHM PERFORMANCE RANKING:\")\n",
    "print(performance_df)\n",
    "\n",
    "\n",
    "best_model_name = performance_df.iloc[0]['Model']\n",
    "best_results = results[best_model_name]\n",
    "\n",
    "print(f\"\\n BEST PERFORMING MODEL: {best_model_name}\")\n",
    "print(f\"   Train RÂ²: {best_results['Train_R2']:.4f} \")\n",
    "print(f\"   Test RÂ²: {best_results['Test_R2']:.4f} \")\n",
    "print(f\"   Overfitting Gap: {best_results['Overfitting_Gap_%']:.1f}%\")\n",
    "print(f\"   Test MAE: â‚¹{best_results['Test_MAE']:.2f}L\")\n",
    "print(f\"   Test RMSE: â‚¹{best_results['Test_RMSE']:.2f}L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be903b88-ea41-4151-90ba-38cc1761d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cross-Validation Analysis for Top 3 Models...\n",
      "\n",
      " Bagging Cross-Validation:\n",
      "   CV RÂ² Scores: ['0.5231', '0.5292', '0.5130', '0.5370', '0.5244']\n",
      "   Mean CV RÂ²: 0.5253\n",
      "   CV Std Dev: 0.0078\n",
      "   CV Range: 0.5130 to 0.5370\n",
      "   Stability: Excellent\n",
      "   CV vs Test consistency: Excellent (diff: 0.0126)\n",
      "\n",
      " AdaBoost Cross-Validation:\n",
      "   CV RÂ² Scores: ['0.4930', '0.5232', '0.4861', '0.5099', '0.5193']\n",
      "   Mean CV RÂ²: 0.5063\n",
      "   CV Std Dev: 0.0145\n",
      "   CV Range: 0.4861 to 0.5232\n",
      "   Stability: Excellent\n",
      "   CV vs Test consistency: Excellent (diff: 0.0067)\n",
      "\n",
      " Random_Forest Cross-Validation:\n",
      "   CV RÂ² Scores: ['0.4756', '0.4908', '0.4573', '0.4671', '0.4792']\n",
      "   Mean CV RÂ²: 0.4740\n",
      "   CV Std Dev: 0.0113\n",
      "   CV Range: 0.4573 to 0.4908\n",
      "   Stability: Excellent\n",
      "   CV vs Test consistency: Excellent (diff: 0.0030)\n",
      "\n",
      " BEST CV PERFORMANCE: Bagging\n",
      "   Mean CV RÂ²: 0.5253\n",
      "   CV Stability: 0.0078\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation on best models\n",
    "print(f\" Cross-Validation Analysis for Top 3 Models...\")\n",
    "\n",
    "top_3_models = performance_df.head(3)['Model'].tolist()\n",
    "\n",
    "cv_results = {}\n",
    "for model_name in top_3_models:\n",
    "    print(f\"\\n {model_name} Cross-Validation:\")\n",
    "    \n",
    "    # Get the model from the models dictionary\n",
    "    model = models[model_name]\n",
    "    cv_scores = cross_val_score(model, X_train_processed, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "    \n",
    "    cv_results[model_name] = {\n",
    "        'scores': cv_scores,\n",
    "        'mean': cv_scores.mean(),\n",
    "        'std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"   CV RÂ² Scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "    print(f\"   Mean CV RÂ²: {cv_scores.mean():.4f}\")\n",
    "    print(f\"   CV Std Dev: {cv_scores.std():.4f}\")\n",
    "    print(f\"   CV Range: {cv_scores.min():.4f} to {cv_scores.max():.4f}\")\n",
    "    \n",
    "    # Stability assessment\n",
    "    stability = \"Excellent\" if cv_scores.std() < 0.02 else \"Good\" if cv_scores.std() < 0.05 else \"Moderate\"\n",
    "    print(f\"   Stability: {stability}\")\n",
    "    \n",
    "    # Compare with test performance\n",
    "    test_cv_diff = abs(cv_scores.mean() - results[model_name]['Test_R2'])\n",
    "    consistency = \"Excellent\" if test_cv_diff < 0.02 else \"Good\" if test_cv_diff < 0.05 else \"Moderate\"\n",
    "    print(f\"   CV vs Test consistency: {consistency} (diff: {test_cv_diff:.4f})\")\n",
    "\n",
    "# Summary of best performing model\n",
    "best_cv_model = max(cv_results.keys(), key=lambda x: cv_results[x]['mean'])\n",
    "print(f\"\\n BEST CV PERFORMANCE: {best_cv_model}\")\n",
    "print(f\"   Mean CV RÂ²: {cv_results[best_cv_model]['mean']:.4f}\")\n",
    "print(f\"   CV Stability: {cv_results[best_cv_model]['std']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

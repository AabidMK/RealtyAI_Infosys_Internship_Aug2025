{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "eSMdOVr5ZUV3",
        "outputId": "e7d65def-64f3-4fb4-dd2d-72840ad969c1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Real Estate Data V21.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-242917431.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Real Estate Data V21.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Real Estate Data V21.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Real Estate Data V21.csv\")\n",
        "print( df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6wzhsJR-RGj",
        "outputId": "bcbb5eac-db18-4fcc-8e8d-64be7e95a818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYLq7mGYYojH",
        "outputId": "2aaec133-00b5-47b2-fd19-f7b37d2bbe2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Preprocessing done. Now X and y are ready for training.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "\n",
        "# Clean price column\n",
        "def clean_price(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    x = str(x).strip().upper()\n",
        "\n",
        "    if \"CR\" in x:  #  if price is in Crores\n",
        "        match = re.findall(r\"[\\d\\.]+\", x)\n",
        "        if match:\n",
        "            return float(match[0]) * 10000000 # we convert in numericals\n",
        "    elif \"L\" in x:  # if prices is in Lakhs\n",
        "        match = re.findall(r\"[\\d\\.]+\", x)\n",
        "        if match:\n",
        "            return float(match[0]) * 100000\n",
        "    else:  # if price is in rupees\n",
        "        match = re.findall(r\"[\\d\\.]+\", x)\n",
        "        if match:\n",
        "            return float(match[0])\n",
        "\n",
        "    return np.nan\n",
        "\n",
        "# Extract number of rooms\n",
        "\n",
        "def extract_rooms(text):\n",
        "    text = str(text).lower()\n",
        "    match = re.search(r'(\\d+(\\.\\d+)?)\\s*bhk', text)# its for bhk\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    match = re.search(r'(\\d+)\\s*bed(room)?', text)# for bedroom\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    match = re.search(r'(\\d+)\\s*rk', text)# for rk\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "# Apply cleaning\n",
        "df['property_title'] = df['Property Title'].astype(str).str.lower()\n",
        "df['num_rooms'] = df['property_title'].apply(extract_rooms)\n",
        "df['Price'] = df['Price'].apply(clean_price)\n",
        "df['Price'] = df['Price'] / 100000  # Convert to Lakhs so that its better to perform calculations\n",
        "\n",
        "#  Handle missing values\n",
        "\n",
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "for col in num_cols:\n",
        "    df[col] = df[col].fillna(df[col].median())# we use median value to replace missing values.\n",
        "\n",
        "# Split location into City & Area\n",
        "df['City'] = df['Location'].apply(lambda x: x.split(',')[-1].strip() if pd.notna(x) else x)\n",
        "df['Area'] = df['Location'].apply(lambda x: x.split(',')[0].strip() if pd.notna(x) else x)\n",
        "\n",
        "# usage of Target Encoding\n",
        "te = TargetEncoder()\n",
        "df['Location_encoded'] = te.fit_transform(df['Location'], df['Price'])\n",
        "df['Balcony_encoded'] = te.fit_transform(df['Balcony'], df['Price'])\n",
        "df['City_encoded'] = te.fit_transform(df['City'], df['Price'])\n",
        "df['Area_encoded'] = te.fit_transform(df['Area'], df['Price'])\n",
        "\n",
        "# Feature selection\n",
        "features = [\n",
        "    'Total_Area', 'Price_per_SQFT', 'Baths', 'num_rooms',\n",
        "    'Location_encoded', 'Balcony_encoded', 'City_encoded', 'Area_encoded'\n",
        "]\n",
        "\n",
        "num_features = ['Total_Area', 'Price_per_SQFT', 'Baths', 'num_rooms']\n",
        "\n",
        "# Apply log1p to numeric features\n",
        "df[num_features] = df[num_features].apply(lambda x: np.log1p(x))\n",
        "\n",
        "X = df[features].copy()\n",
        "y = np.log1p(df['Price'])  # log transform target\n",
        "\n",
        "# Scale numeric features (scaling)\n",
        "scaler = StandardScaler()\n",
        "X[num_features] = scaler.fit_transform(X[num_features])\n",
        "\n",
        "print(\" Preprocessing done. Now X and y are ready for training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMjLHfDN_oBd"
      },
      "source": [
        "Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGvC7FEtaCjf",
        "outputId": "188de55e-d8bc-4d1f-ce14-5892f873ab98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression - Train:\n",
            " R²: 0.7389607449433809\n",
            " MAE: 0.23812032152697027\n",
            " RMSE: 0.4479769284637357\n",
            "\n",
            "Linear Regression - Test:\n",
            " R²: 0.7838239412710939\n",
            " MAE: 0.22531496264723874\n",
            " RMSE: 0.3988310045135304\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Splitting Train-test data ie 20 % for testing and 80% for traning\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Linear refression model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = lin_reg.predict(X_train)\n",
        "y_test_pred = lin_reg.predict(X_test)\n",
        "\n",
        "# Metrics of linear regression\n",
        "print(\"Linear Regression - Train:\")\n",
        "print(\" R²:\", r2_score(y_train, y_train_pred))\n",
        "print(\" MAE:\", mean_absolute_error(y_train, y_train_pred))\n",
        "print(\" RMSE:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
        "\n",
        "print(\"\\nLinear Regression - Test:\")\n",
        "print(\" R²:\", r2_score(y_test, y_test_pred))\n",
        "print(\" MAE:\", mean_absolute_error(y_test, y_test_pred))\n",
        "print(\" RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZdwRaO7_rnv"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szp-rqGYaDcR",
        "outputId": "df72261f-792c-4f09-ebd5-c98a9b1069c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree - Train:\n",
            " R²: 0.9940873180086722\n",
            " MAE: 0.046798271715229336\n",
            " RMSE: 0.06742097018838518\n",
            "\n",
            "Decision Tree - Test:\n",
            " R²: 0.9712051359346269\n",
            " MAE: 0.06603492719750219\n",
            " RMSE: 0.1455601958849262\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = dt.predict(X_train)\n",
        "y_test_pred = dt.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree - Train:\")\n",
        "print(\" R²:\", r2_score(y_train, y_train_pred))\n",
        "print(\" MAE:\", mean_absolute_error(y_train, y_train_pred))\n",
        "print(\" RMSE:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
        "\n",
        "print(\"\\nDecision Tree - Test:\")\n",
        "print(\" R²:\", r2_score(y_test, y_test_pred))\n",
        "print(\" MAE:\", mean_absolute_error(y_test, y_test_pred))\n",
        "print(\" RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPmOuKMC_uU2"
      },
      "source": [
        "RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AhABDtUqXi4",
        "outputId": "d3fc28da-e2c4-4587-d465-7ce7c63fca12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library and models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# Models\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor, ExtraTreesRegressor,\n",
        "    GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
        ")\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "ywEBLaQiuGg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "df = pd.read_csv(\"/content/Real Estate Data V21.csv\")"
      ],
      "metadata": {
        "id": "lPwpNxQXuj0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning Function\n",
        "and room Extraction"
      ],
      "metadata": {
        "id": "XpjKYINCuUeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Data Cleaning Functions\n",
        "# ============================================\n",
        "\n",
        "def clean_price(x):\n",
        "    \"\"\"Convert Price strings (Cr/Lakh/₹) into numeric (₹).\"\"\"\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    x = str(x).strip().upper()\n",
        "    if \"CR\" in x:\n",
        "        match = re.findall(r\"[\\d\\.]+\", x)\n",
        "        if match:\n",
        "            return float(match[0]) * 10000000\n",
        "    elif \"L\" in x:\n",
        "        match = re.findall(r\"[\\d\\.]+\", x)\n",
        "        if match:\n",
        "            return float(match[0]) * 100000\n",
        "    else:\n",
        "        match = re.findall(r\"[\\d\\.]+\", x)\n",
        "        if match:\n",
        "            return float(match[0])\n",
        "    return np.nan\n",
        "\n",
        "def extract_rooms(text):\n",
        "    \"\"\"Extract number of rooms from property title text.\"\"\"\n",
        "    text = str(text).lower()\n",
        "    match = re.search(r'(\\d+(\\.\\d+)?)\\s*bhk', text)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    match = re.search(r'(\\d+)\\s*bed(room)?', text)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    match = re.search(r'(\\d+)\\s*rk', text)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "2lRC-_ssuTli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Preprocessing\n",
        "# ============================================\n",
        "\n",
        "# Extract rooms from property title\n",
        "df['property_title'] = df['Property Title'].astype(str).str.lower()\n",
        "df['num_rooms'] = df['property_title'].apply(extract_rooms)\n",
        "\n",
        "# Clean price and convert to Lakhs\n",
        "df['Price'] = df['Price'].apply(clean_price) / 100000\n",
        "\n",
        "# Remove outliers\n",
        "df = df[df['Price'] <= 200]\n",
        "\n",
        "# Fill missing numeric values with median\n",
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "for col in num_cols:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Split Location into City & Area\n",
        "df['City'] = df['Location'].apply(lambda x: x.split(',')[-1].strip() if pd.notna(x) else x)\n",
        "df['Area'] = df['Location'].apply(lambda x: x.split(',')[0].strip() if pd.notna(x) else x)\n"
      ],
      "metadata": {
        "id": "qxSgkh9RuaER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Encoder\n"
      ],
      "metadata": {
        "id": "fZWnq0mKuvfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Target Encoding\n",
        "# ============================================\n",
        "\n",
        "te = TargetEncoder()\n",
        "df['Location_encoded'] = te.fit_transform(df['Location'], df['Price'])\n",
        "df['Balcony_encoded'] = te.fit_transform(df['Balcony'], df['Price'])\n",
        "df['City_encoded'] = te.fit_transform(df['City'], df['Price'])\n",
        "df['Area_encoded'] = te.fit_transform(df['Area'], df['Price'])\n"
      ],
      "metadata": {
        "id": "YMVAoTXux1Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection and Scaling"
      ],
      "metadata": {
        "id": "4OFIfqFHuz__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Features, Log-transform & Scaling\n",
        "# ============================================\n",
        "\n",
        "features = [\n",
        "    'Total_Area', 'Price_per_SQFT', 'Baths', 'num_rooms',\n",
        "    'Location_encoded', 'Balcony_encoded', 'City_encoded', 'Area_encoded'\n",
        "]\n",
        "num_features = ['Total_Area', 'Price_per_SQFT', 'Baths', 'num_rooms']\n",
        "\n",
        "# Log-transform numeric features\n",
        "df[num_features] = df[num_features].apply(lambda x: np.log1p(x))\n",
        "\n",
        "X = df[features].copy()\n",
        "y = np.log1p(df['Price'])  # log-transform target\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X[num_features] = scaler.fit_transform(X[num_features])\n"
      ],
      "metadata": {
        "id": "26_I2Gwrx3IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Train-Test Split\n",
        "# ============================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZAP97nq6uy-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "NDXEkOAsu_RC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Models\n"
      ],
      "metadata": {
        "id": "biF9jNUSvDr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# Define Models\n",
        "# ============================================\n",
        "\n",
        "models = {\n",
        "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=200, random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=200, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=200, random_state=42),\n",
        "    \"Bagging\": BaggingRegressor(n_estimators=200, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=200, random_state=42, objective=\"reg:squarederror\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "W6BPCy9LvCpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and evaluation"
      ],
      "metadata": {
        "id": "W3Mo03DHvVg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Training & Evaluation\n",
        "# ============================================\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Train predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_train_true = np.expm1(y_train)\n",
        "    y_train_pred_true = np.expm1(y_train_pred)\n",
        "\n",
        "    # Test predictions\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_test_true = np.expm1(y_test)\n",
        "    y_test_pred_true = np.expm1(y_test_pred)\n",
        "\n",
        "    # Metrics\n",
        "    train_r2 = r2_score(y_train_true, y_train_pred_true)\n",
        "    test_r2 = r2_score(y_test_true, y_test_pred_true)\n",
        "    train_mae = mean_absolute_error(y_train_true, y_train_pred_true)\n",
        "    test_mae = mean_absolute_error(y_test_true, y_test_pred_true)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train_true, y_train_pred_true))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred_true))\n",
        "\n",
        "    results[name] = {\n",
        "        \"Train_R2(%)\": round(train_r2 * 100, 2),\n",
        "        \"Test_R2(%)\": round(test_r2 * 100, 2),\n",
        "        \"Overfit_Gap(%)\": round((train_r2 - test_r2) * 100, 2),\n",
        "        \"Train_MAE (Lakhs)\": round(train_mae, 2),\n",
        "        \"Test_MAE (Lakhs)\": round(test_mae, 2),\n",
        "        \"Train_RMSE (Lakhs)\": round(train_rmse, 2),\n",
        "        \"Test_RMSE (Lakhs)\": round(test_rmse, 2),\n",
        "    }\n",
        "\n",
        "results_df = pd.DataFrame(results).T.sort_values(by=\"Test_R2(%)\", ascending=False)\n",
        "print(\"\\n================== Optimized Model Performance ==================\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc8e8WKNvTlo",
        "outputId": "aa8a8a54-a70a-4896-8142-0c185fc40e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================== Optimized Model Performance ==================\n",
            "                  Train_R2(%)  Test_R2(%)  Overfit_Gap(%)  Train_MAE (Lakhs)  \\\n",
            "RandomForest            99.74       99.24            0.50               0.58   \n",
            "Bagging                 99.75       99.23            0.52               0.58   \n",
            "XGBoost                 99.93       99.06            0.87               0.76   \n",
            "GradientBoosting        99.05       98.97            0.08               2.38   \n",
            "ExtraTrees             100.00       98.57            1.43               0.00   \n",
            "DecisionTree           100.00       97.81            2.19               0.00   \n",
            "AdaBoost                54.79       54.59            0.20              18.81   \n",
            "\n",
            "                  Test_MAE (Lakhs)  Train_RMSE (Lakhs)  Test_RMSE (Lakhs)  \n",
            "RandomForest                  1.32                2.24               3.81  \n",
            "Bagging                       1.33                2.21               3.84  \n",
            "XGBoost                       2.01                1.16               4.24  \n",
            "GradientBoosting              2.57                4.31               4.46  \n",
            "ExtraTrees                    1.83                0.00               5.23  \n",
            "DecisionTree                  2.24                0.00               6.48  \n",
            "AdaBoost                     19.04               29.71              29.52  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4KnulMZzO_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}